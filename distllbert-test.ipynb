{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-31T19:16:10.621871Z",
     "start_time": "2025-03-31T19:16:10.617871Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from utilities import read_xml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from utilities import clean_description\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from datasets import Dataset, DatasetDict\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:16:14.589498Z",
     "start_time": "2025-03-31T19:16:10.640026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import\n",
    "PATH_DEV = os.path.join(os.getcwd(), 'origdata', 'BlurbGenreCollection_EN_dev.txt')\n",
    "PATH_TEST = os.path.join(os.getcwd(), 'origdata', 'BlurbGenreCollection_EN_test.txt')\n",
    "PATH_TRAIN = os.path.join(os.getcwd(), 'origdata', 'BlurbGenreCollection_EN_train.txt')\n",
    "\n",
    "df_train = read_xml(PATH_TRAIN)\n",
    "df_test = read_xml(PATH_TEST)\n",
    "df_dev = read_xml(PATH_DEV)\n",
    "\n",
    "frames = [df_train, df_test, df_dev]\n",
    "df = pd.concat(frames).reset_index(drop=True)"
   ],
   "id": "fe6bc5ade67ff20d",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:16:14.797359Z",
     "start_time": "2025-03-31T19:16:14.606559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 166 topics reduced to 7\n",
    "reduced_topics = [\n",
    "    \"Fiction\", \"Children’s Books\", \"Nonfiction\",\n",
    "    \"Poetry\", \"Humor\", \"Classics\", \"Young Adult\"\n",
    "]\n",
    "\n",
    "def assign_primary_topic(topic_string):\n",
    "    # Split topic-string into a list of individual topics\n",
    "    topics = [t.strip() for t in re.split(r',\\s*', topic_string)]\n",
    "    for reduced_topic in reduced_topics:\n",
    "        for t in topics:\n",
    "            if reduced_topic.lower() in t.lower():\n",
    "                return reduced_topic\n",
    "    return \"Other\"\n",
    "\n",
    "df['TOPIC_MAIN'] = df['TOPICS'].apply(assign_primary_topic)\n",
    "df = df[df['TOPIC_MAIN'] != \"Other\"]"
   ],
   "id": "a1ebb70ef637a495",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:16:39.302152Z",
     "start_time": "2025-03-31T19:16:14.815916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clean Descriptions\n",
    "df['DESCRIPTION'] = df['DESCRIPTION'].fillna('').apply(clean_description)\n",
    "df.drop(77427, inplace=True)"
   ],
   "id": "58a88b20e8f8af7b",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:16:40.078305Z",
     "start_time": "2025-03-31T19:16:39.321178Z"
    }
   },
   "cell_type": "code",
   "source": "df['word_count'] = df['DESCRIPTION'].str.split().str.len()",
   "id": "a262d02182fea2d",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:16:40.253148Z",
     "start_time": "2025-03-31T19:16:40.246630Z"
    }
   },
   "cell_type": "code",
   "source": "df[df['word_count'] ==0] # no zero word descriptions found",
   "id": "8fc55897c9c728a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [TITLE, AUTHOR, PUBLISHED, ISBN, PAGE_NUM, URL, TOPICS, COPYRIGHT, DESCRIPTION, DATE, LANGUAGE, TOPIC_MAIN, word_count]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>PUBLISHED</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>PAGE_NUM</th>\n",
       "      <th>URL</th>\n",
       "      <th>TOPICS</th>\n",
       "      <th>COPYRIGHT</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>TOPIC_MAIN</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:16:40.308808Z",
     "start_time": "2025-03-31T19:16:40.294757Z"
    }
   },
   "cell_type": "code",
   "source": "train_df, test_df = train_test_split(df[['DESCRIPTION', 'TOPIC_MAIN']], test_size=0.2, random_state=42)",
   "id": "85bec54d58ca2b40",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:16:40.341889Z",
     "start_time": "2025-03-31T19:16:40.336861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(train_df.shape) # (73515, 3)\n",
    "print(test_df.shape) # (18379, 3)"
   ],
   "id": "20392e698fe50dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73514, 2)\n",
      "(18379, 2)\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:16:40.482445Z",
     "start_time": "2025-03-31T19:16:40.476388Z"
    }
   },
   "cell_type": "code",
   "source": "train_df",
   "id": "568a6fb6a05c0660",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             DESCRIPTION        TOPIC_MAIN\n",
       "63724  This daring, star-packed collection is the fan...           Fiction\n",
       "14608  With her soft heart and angelic face, Madeline...           Fiction\n",
       "72346  NEW YORK TIMES BESTSELLER * A deeply affecting...           Fiction\n",
       "12024  ONE CHILL EVENING IN BETHLEHEM, young Naomi he...  Children’s Books\n",
       "16203  All original stories about the return of Cthul...           Fiction\n",
       "...                                                  ...               ...\n",
       "6265   Following a wild and raging storm, the Swiss f...  Children’s Books\n",
       "54886  A family-focused guidebook to Italy for travel...           Fiction\n",
       "76820  A single volume of the most beautiful texts by...            Poetry\n",
       "860    The Truth Chasers Book Three. Someone's trying...           Fiction\n",
       "15795  ISABEL DALHOUSIE - Book 8 Nothing captures the...           Fiction\n",
       "\n",
       "[73514 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>TOPIC_MAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63724</th>\n",
       "      <td>This daring, star-packed collection is the fan...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14608</th>\n",
       "      <td>With her soft heart and angelic face, Madeline...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72346</th>\n",
       "      <td>NEW YORK TIMES BESTSELLER * A deeply affecting...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12024</th>\n",
       "      <td>ONE CHILL EVENING IN BETHLEHEM, young Naomi he...</td>\n",
       "      <td>Children’s Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16203</th>\n",
       "      <td>All original stories about the return of Cthul...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>Following a wild and raging storm, the Swiss f...</td>\n",
       "      <td>Children’s Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>A family-focused guidebook to Italy for travel...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>A single volume of the most beautiful texts by...</td>\n",
       "      <td>Poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>The Truth Chasers Book Three. Someone's trying...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>ISABEL DALHOUSIE - Book 8 Nothing captures the...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73514 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:16:40.540450Z",
     "start_time": "2025-03-31T19:16:40.533449Z"
    }
   },
   "cell_type": "code",
   "source": "test_df",
   "id": "fc02c00d1b3ad8c5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             DESCRIPTION        TOPIC_MAIN\n",
       "62081  This lexicon of modern Western philosophical c...           Fiction\n",
       "18176  Emily-and her new band, the Strangers-won the ...  Children’s Books\n",
       "19140  A perfect graudation gift all about growing up...  Children’s Books\n",
       "16534  Even a bookish big sister is drawn in by the p...  Children’s Books\n",
       "21974  Where Can You Find the Kind of Love You Truly ...           Fiction\n",
       "...                                                  ...               ...\n",
       "458    In a small, dusty town in India, Sripathi Rao ...           Fiction\n",
       "25026  The Limits to Capital provides one of the best...           Fiction\n",
       "73035  How climate change will affect our political t...           Fiction\n",
       "43431  When a woman's body washes up on the shore of ...           Fiction\n",
       "46734  This book takes the reader on a fantastic jour...           Fiction\n",
       "\n",
       "[18379 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>TOPIC_MAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62081</th>\n",
       "      <td>This lexicon of modern Western philosophical c...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18176</th>\n",
       "      <td>Emily-and her new band, the Strangers-won the ...</td>\n",
       "      <td>Children’s Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19140</th>\n",
       "      <td>A perfect graudation gift all about growing up...</td>\n",
       "      <td>Children’s Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16534</th>\n",
       "      <td>Even a bookish big sister is drawn in by the p...</td>\n",
       "      <td>Children’s Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21974</th>\n",
       "      <td>Where Can You Find the Kind of Love You Truly ...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>In a small, dusty town in India, Sripathi Rao ...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25026</th>\n",
       "      <td>The Limits to Capital provides one of the best...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73035</th>\n",
       "      <td>How climate change will affect our political t...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43431</th>\n",
       "      <td>When a woman's body washes up on the shore of ...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46734</th>\n",
       "      <td>This book takes the reader on a fantastic jour...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18379 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:16:40.602193Z",
     "start_time": "2025-03-31T19:16:40.595192Z"
    }
   },
   "cell_type": "code",
   "source": "print(df['DESCRIPTION'].isnull().sum())",
   "id": "4c7a4100d3bcabfe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:16:55.108937Z",
     "start_time": "2025-03-31T19:16:40.639263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert categorical labels (topics) to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['label'] = label_encoder.fit_transform(train_df['TOPIC_MAIN'])\n",
    "test_df['label'] = label_encoder.transform(test_df['TOPIC_MAIN'])\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train_df[['DESCRIPTION', 'label']]),\n",
    "    'test': Dataset.from_pandas(test_df[['DESCRIPTION', 'label']])\n",
    "})\n",
    "\n",
    "# Load  pre-trained DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    texts = [str(text) if text is not None else \"\" for text in batch['DESCRIPTION']]\n",
    "    # tokenize text with padding and truncate for consistent input length\n",
    "    return tokenizer(texts, padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Apply function to entire dataset\n",
    "dataset = dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Remove 'DESCRIPTION' column, as it's not needed after tokenization\n",
    "dataset = dataset.remove_columns(['DESCRIPTION'])\n",
    "\n",
    "# Set the format of the dataset to PyTorch tensors\n",
    "dataset.set_format(\"torch\")"
   ],
   "id": "afe75d99902997d2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorenz\\anaconda3\\envs\\cudatest\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "                                                                   \r"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:16:55.116830Z",
     "start_time": "2025-03-31T19:16:55.112938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup device for GPU usage\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")"
   ],
   "id": "cf4a09a085b85fed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 4070 Ti is available.\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:16:55.159743Z",
     "start_time": "2025-03-31T19:16:55.136126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "id": "bdb7cb5cb9d1505f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:37:33.110814Z",
     "start_time": "2025-03-31T19:16:55.265651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the pre-trained DistilBERT model for sequence classification\n",
    "# + specify num_labels (number of unique topics)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=len(label_encoder.classes_))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\", # directory where model/checkpoints are saved\n",
    "    evaluation_strategy=\"epoch\", # evaluate at the end of epoch\n",
    "    save_strategy=\"epoch\", # save model each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16, # consumes about 7GB of VRAM\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2, # two training epochs\n",
    "    weight_decay=0.01,# weight decay to prevent overfitting\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10, # log each ten steps\n",
    "    no_cuda=False, # force gpu usage\n",
    "    fp16=True, # mixed precision to speed up training\n",
    ")\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    # Override create_optimizer method to use AdamW optimizer with fused kernel for efficiency\n",
    "    def create_optimizer(self):\n",
    "        if self.optimizer is None:\n",
    "            # Create the AdamW optimizer and pass in model parameters and the learning rate\n",
    "            self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=training_args.learning_rate, fused=True)\n",
    "        return self.optimizer\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"]\n",
    ")\n",
    "\n",
    "# Start training the model\n",
    "trainer.train()"
   ],
   "id": "f754b63b1ef69433",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorenz\\anaconda3\\envs\\cudatest\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Lorenz\\anaconda3\\envs\\cudatest\\lib\\site-packages\\accelerate\\accelerator.py:450: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9190' max='9190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9190/9190 20:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.100600</td>\n",
       "      <td>0.137772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.040700</td>\n",
       "      <td>0.147777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9190, training_loss=0.1401493052330772, metrics={'train_runtime': 1237.0915, 'train_samples_per_second': 118.85, 'train_steps_per_second': 7.429, 'total_flos': 1.947745869232128e+16, 'train_loss': 0.1401493052330772, 'epoch': 2.0})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:50:45.700918Z",
     "start_time": "2025-03-31T19:50:45.228343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load saved model from results directory\n",
    "saved_model = DistilBertForSequenceClassification.from_pretrained(\"./results/checkpoint-9190\", num_labels=len(label_encoder.classes_))\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to chosen device (GPU or CPU)\n",
    "saved_model.to(device)"
   ],
   "id": "d2a14c3d1e6a168c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:57:30.919172Z",
     "start_time": "2025-03-31T19:57:30.911139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_topic(description):\n",
    "    # Tokenize the description\n",
    "    inputs = tokenizer(description, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    # Move inputs to the device (GPU or CPU)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    # Get the model's logits (raw prediction scores)\n",
    "    with torch.no_grad():\n",
    "        logits = saved_model(**inputs).logits\n",
    "\n",
    "    # Get the predicted label (index of the maximum logit)\n",
    "    predicted_label_idx = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Convert the label index to the topic name using the label_encoder\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_label_idx])[0]\n",
    "\n",
    "    return predicted_label\n",
    "\n",
    "def predict_top_3(description):\n",
    "    # Tokenize the input description\n",
    "    inputs = tokenizer(description, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    # Move inputs to the device (GPU or CPU)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    # Get the model's logits (raw prediction scores)\n",
    "    with torch.no_grad():\n",
    "        logits = saved_model(**inputs).logits\n",
    "\n",
    "    # Get the top 3 predictions based on the logits (softmax to get probabilities)\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "    # Get top 3 predictions\n",
    "    top_3_values, top_3_indices = torch.topk(probs, 3, dim=-1)\n",
    "\n",
    "    # Convert to numpy and get the predicted labels\n",
    "    top_3_values = top_3_values.cpu().numpy().flatten()  # Get probabilities\n",
    "    top_3_indices = top_3_indices.cpu().numpy().flatten()  # Get indices of the topics\n",
    "\n",
    "    top_3_topics = label_encoder.inverse_transform(top_3_indices)\n",
    "\n",
    "    return list(zip(top_3_topics, top_3_values))"
   ],
   "id": "dfc716c62be2941f",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:57:32.183820Z",
     "start_time": "2025-03-31T19:57:32.110676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_description = \"A thrilling adventure set in a fantastical world.\"\n",
    "predicted_topic = predict_topic(new_description)\n",
    "predicted_top_3 = predict_top_3(new_description)\n",
    "\n",
    "print(f\"The predicted topic for the description is: {predicted_topic}\")\n",
    "for topic, prob in predicted_top_3:\n",
    "    print(f\"{topic}: {prob:.4f} %\")"
   ],
   "id": "bde3ae40fb62c18f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted topic for the description is: Children’s Books\n",
      "Children’s Books: 0.9812 %\n",
      "Fiction: 0.0184 %\n",
      "Humor: 0.0001 %\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e6e64ece8dc0f56d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
